#!/usr/bin/env python3
"""
Insider Trading Network Graph ‚Äî Phase 91

Map corporate insider relationships, track synchronized buying/selling patterns,
detect coordinated activity clusters, visualize influence networks with centrality scoring.

Analyzes:
1. Form 4 insider transactions from SEC EDGAR
2. Relationship graphs between insiders (shared companies, transaction timing)
3. Coordinated trading patterns (synchronized buys/sells within time windows)
4. Network centrality metrics (key influencers, information hubs)
5. Cluster detection (groups of connected insiders acting together)

Free data sources:
- SEC EDGAR Form 4 filings (insider transactions)
- Network analysis using basic graph algorithms
"""

import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Set
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
import json
import time
import re


@dataclass
class InsiderTransaction:
    """Single insider transaction from Form 4."""
    ticker: str
    company_name: str
    insider_name: str
    insider_title: str
    transaction_date: str
    shares: int
    transaction_type: str  # BUY, SELL, GRANT, OPTION_EXERCISE
    price: float
    total_value: float
    shares_owned_after: int
    is_direct: bool  # Direct vs indirect ownership
    filing_date: str
    form_url: str


@dataclass
class InsiderProfile:
    """Profile of a single insider across all companies."""
    name: str
    companies: List[str]  # All companies where this insider has positions
    titles: List[str]  # All titles held
    total_transactions: int
    total_buy_value: float
    total_sell_value: float
    net_position: float  # Buy - sell
    first_transaction: str
    last_transaction: str
    connected_insiders: List[str]  # Other insiders with shared companies


@dataclass
class CoordinatedActivity:
    """Detected coordinated trading activity."""
    insiders: List[str]
    companies: List[str]
    transaction_type: str  # BUY, SELL, MIXED
    time_window_days: int
    transactions: int
    total_value: float
    start_date: str
    end_date: str
    confidence: float  # 0-100, based on timing and magnitude


@dataclass
class NetworkMetrics:
    """Network centrality and influence metrics."""
    name: str
    degree_centrality: float  # Number of direct connections
    betweenness_centrality: float  # Bridge between network clusters
    closeness_centrality: float  # Average distance to all other nodes
    clustering_coefficient: float  # How connected are neighbors
    influence_score: float  # Combined metric (0-100)


@dataclass
class InsiderCluster:
    """Detected cluster of connected insiders."""
    cluster_id: int
    members: List[str]
    size: int
    companies: List[str]
    total_transaction_value: float
    avg_transaction_sync: float  # Average days between coordinated trades
    cluster_type: str  # EXECUTIVE_GROUP, BOARD_NETWORK, CROSS_COMPANY


@dataclass
class InsiderNetworkReport:
    """Full insider trading network analysis."""
    analysis_date: str
    tickers: List[str]
    total_insiders: int
    total_transactions: int
    time_range_days: int
    top_insiders: List[InsiderProfile]
    coordinated_activities: List[CoordinatedActivity]
    network_metrics: List[NetworkMetrics]
    clusters: List[InsiderCluster]
    buy_sell_ratio: float
    summary: str
    red_flags: List[str]


class InsiderNetworkAnalyzer:
    """Analyze insider trading networks and detect coordinated activity."""
    
    # SEC EDGAR configuration
    IDENTITY = "MoneyClaw Bot team@moneyclaw.com"
    HEADERS = {"User-Agent": IDENTITY, "Accept-Encoding": "gzip, deflate"}
    BASE_URL = "https://data.sec.gov"
    RATE_LIMIT_DELAY = 0.12  # SEC allows 10 req/sec
    
    # Coordination detection parameters
    COORDINATION_WINDOW_DAYS = 5  # Trades within 5 days considered potentially coordinated
    MIN_COORDINATED_TRADES = 3  # Minimum trades to flag as coordinated
    MIN_COORDINATION_VALUE = 1_000_000  # Minimum dollar value to flag
    
    def __init__(self):
        self._last_request = 0
        self._cik_cache = {}
        
    def _throttle(self):
        """Respect SEC rate limits."""
        elapsed = time.time() - self._last_request
        if elapsed < self.RATE_LIMIT_DELAY:
            time.sleep(self.RATE_LIMIT_DELAY - elapsed)
        self._last_request = time.time()
    
    def _get_cik(self, ticker: str) -> str:
        """Resolve ticker to CIK (zero-padded to 10 digits)."""
        if ticker in self._cik_cache:
            return self._cik_cache[ticker]
        
        self._throttle()
        url = "https://www.sec.gov/files/company_tickers.json"
        r = requests.get(url, headers=self.HEADERS, timeout=30)
        r.raise_for_status()
        data = r.json()
        
        for entry in data.values():
            if entry["ticker"].upper() == ticker.upper():
                cik = str(entry["cik_str"]).zfill(10)
                self._cik_cache[ticker] = cik
                return cik
        
        raise ValueError(f"Ticker {ticker} not found in SEC database")
    
    def fetch_insider_trades(self, ticker: str, days: int = 365) -> List[InsiderTransaction]:
        """Fetch Form 4 insider trades from SEC EDGAR."""
        try:
            # Use the existing sec_edgar module
            import sys
            import os
            sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
            from sec_edgar import insider_trades as get_insider_trades
            
            data = get_insider_trades(ticker, limit=100)
            trades_data = data.get("trades", [])
            
            transactions = []
            for trade in trades_data:
                # Parse the basic data available from SEC search
                filed_date = trade.get("filed", "")
                entity = trade.get("entity", "")
                description = trade.get("description", [])
                
                # Create a simplified transaction record
                # Note: Full Form 4 parsing would require XML parsing of each filing
                if filed_date and entity:
                    transactions.append(InsiderTransaction(
                        ticker=ticker,
                        company_name=entity,
                        insider_name=description[0] if description else "Unknown",
                        insider_title="Officer/Director",  # Would need Form 4 XML for exact title
                        transaction_date=filed_date,
                        shares=1000,  # Placeholder - would parse from Form 4 XML
                        transaction_type="BUY",  # Placeholder - would parse from Form 4 XML
                        price=100.0,  # Placeholder - would parse from Form 4 XML
                        total_value=100000.0,  # Placeholder
                        shares_owned_after=10000,  # Placeholder
                        is_direct=True,
                        filing_date=filed_date,
                        form_url=f"https://www.sec.gov/cgi-bin/browse-edgar"
                    ))
            
            print(f"Fetched {len(transactions)} insider filings for {ticker}")
            print(f"Note: Using simplified Form 4 data. Full transaction details require XML parsing.")
            
            return transactions
            
        except Exception as e:
            print(f"Warning: Could not fetch insider data for {ticker}: {e}")
            return []
    
    def build_insider_profiles(self, transactions: List[InsiderTransaction]) -> Dict[str, InsiderProfile]:
        """Build profiles for all insiders from transaction history."""
        profiles = defaultdict(lambda: {
            'companies': set(),
            'titles': set(),
            'transactions': [],
            'buy_value': 0,
            'sell_value': 0
        })
        
        for txn in transactions:
            name = txn.insider_name
            profiles[name]['companies'].add(txn.ticker)
            profiles[name]['titles'].add(txn.insider_title)
            profiles[name]['transactions'].append(txn)
            
            if txn.transaction_type == 'BUY':
                profiles[name]['buy_value'] += txn.total_value
            elif txn.transaction_type == 'SELL':
                profiles[name]['sell_value'] += txn.total_value
        
        # Build connected insiders (shared companies)
        result = {}
        for name, data in profiles.items():
            connected = set()
            for other_name, other_data in profiles.items():
                if name != other_name:
                    shared_companies = data['companies'] & other_data['companies']
                    if shared_companies:
                        connected.add(other_name)
            
            txns = data['transactions']
            dates = [datetime.strptime(t.transaction_date, '%Y-%m-%d') for t in txns]
            
            result[name] = InsiderProfile(
                name=name,
                companies=sorted(data['companies']),
                titles=sorted(data['titles']),
                total_transactions=len(txns),
                total_buy_value=data['buy_value'],
                total_sell_value=data['sell_value'],
                net_position=data['buy_value'] - data['sell_value'],
                first_transaction=min(dates).strftime('%Y-%m-%d') if dates else '',
                last_transaction=max(dates).strftime('%Y-%m-%d') if dates else '',
                connected_insiders=sorted(connected)
            )
        
        return result
    
    def detect_coordinated_activity(
        self,
        transactions: List[InsiderTransaction],
        window_days: int = None
    ) -> List[CoordinatedActivity]:
        """Detect coordinated trading patterns (synchronized buys/sells)."""
        if window_days is None:
            window_days = self.COORDINATION_WINDOW_DAYS
        
        # Group transactions by time windows
        by_date = defaultdict(list)
        for txn in transactions:
            by_date[txn.transaction_date].append(txn)
        
        coordinated = []
        dates = sorted(by_date.keys())
        
        for i, start_date in enumerate(dates):
            start_dt = datetime.strptime(start_date, '%Y-%m-%d')
            end_dt = start_dt + timedelta(days=window_days)
            
            # Collect transactions in window
            window_txns = []
            for date in dates[i:]:
                dt = datetime.strptime(date, '%Y-%m-%d')
                if dt > end_dt:
                    break
                window_txns.extend(by_date[date])
            
            if len(window_txns) < self.MIN_COORDINATED_TRADES:
                continue
            
            # Group by transaction type
            by_type = defaultdict(list)
            for txn in window_txns:
                by_type[txn.transaction_type].append(txn)
            
            # Check for coordinated buys or sells
            for txn_type, txns in by_type.items():
                if len(txns) < self.MIN_COORDINATED_TRADES:
                    continue
                
                insiders = list(set(t.insider_name for t in txns))
                companies = list(set(t.ticker for t in txns))
                total_value = sum(t.total_value for t in txns)
                
                if total_value < self.MIN_COORDINATION_VALUE:
                    continue
                
                # Calculate confidence score
                confidence = min(100, (
                    (len(insiders) / 10 * 40) +  # More insiders = higher confidence
                    (min(total_value / 10_000_000, 1) * 40) +  # Larger value = higher
                    (min(len(txns) / 10, 1) * 20)  # More transactions = higher
                ))
                
                coordinated.append(CoordinatedActivity(
                    insiders=insiders,
                    companies=companies,
                    transaction_type=txn_type,
                    time_window_days=window_days,
                    transactions=len(txns),
                    total_value=total_value,
                    start_date=min(t.transaction_date for t in txns),
                    end_date=max(t.transaction_date for t in txns),
                    confidence=round(confidence, 1)
                ))
        
        return sorted(coordinated, key=lambda x: x.confidence, reverse=True)
    
    def calculate_network_metrics(self, profiles: Dict[str, InsiderProfile]) -> List[NetworkMetrics]:
        """Calculate network centrality metrics for each insider."""
        metrics = []
        
        # Build adjacency matrix
        names = list(profiles.keys())
        n = len(names)
        name_to_idx = {name: i for i, name in enumerate(names)}
        
        # Adjacency matrix (1 if connected, 0 otherwise)
        adj_matrix = np.zeros((n, n))
        for name, profile in profiles.items():
            i = name_to_idx[name]
            for connected in profile.connected_insiders:
                if connected in name_to_idx:
                    j = name_to_idx[connected]
                    adj_matrix[i][j] = 1
        
        for name, profile in profiles.items():
            i = name_to_idx[name]
            
            # Degree centrality: number of connections / max possible
            degree = np.sum(adj_matrix[i])
            degree_centrality = degree / (n - 1) if n > 1 else 0
            
            # Betweenness centrality: simplified version (full BFS implementation omitted for brevity)
            betweenness = self._calculate_betweenness(adj_matrix, i)
            
            # Closeness centrality: 1 / average distance to all other nodes
            closeness = self._calculate_closeness(adj_matrix, i)
            
            # Clustering coefficient: how connected are neighbors
            clustering = self._calculate_clustering(adj_matrix, i)
            
            # Combined influence score
            influence = (
                degree_centrality * 40 +
                betweenness * 30 +
                closeness * 20 +
                clustering * 10
            )
            
            metrics.append(NetworkMetrics(
                name=name,
                degree_centrality=round(degree_centrality, 3),
                betweenness_centrality=round(betweenness, 3),
                closeness_centrality=round(closeness, 3),
                clustering_coefficient=round(clustering, 3),
                influence_score=round(influence, 1)
            ))
        
        return sorted(metrics, key=lambda x: x.influence_score, reverse=True)
    
    def _calculate_betweenness(self, adj_matrix: np.ndarray, node: int) -> float:
        """Simplified betweenness centrality (fraction of shortest paths through node)."""
        n = len(adj_matrix)
        if n <= 2:
            return 0
        
        # Count shortest paths that go through this node using BFS
        paths_through = 0
        total_paths = 0
        
        for source in range(n):
            if source == node:
                continue
            for target in range(source + 1, n):
                if target == node:
                    continue
                
                # BFS to find shortest path
                if self._path_goes_through(adj_matrix, source, target, node):
                    paths_through += 1
                total_paths += 1
        
        return paths_through / total_paths if total_paths > 0 else 0
    
    def _path_goes_through(self, adj_matrix: np.ndarray, source: int, target: int, node: int) -> bool:
        """Check if shortest path from source to target goes through node."""
        n = len(adj_matrix)
        
        # BFS from source
        visited = [False] * n
        parent = [-1] * n
        queue = deque([source])
        visited[source] = True
        
        while queue:
            current = queue.popleft()
            if current == target:
                break
            
            for neighbor in range(n):
                if adj_matrix[current][neighbor] and not visited[neighbor]:
                    visited[neighbor] = True
                    parent[neighbor] = current
                    queue.append(neighbor)
        
        if not visited[target]:
            return False
        
        # Reconstruct path
        path = []
        current = target
        while current != -1:
            path.append(current)
            current = parent[current]
        
        return node in path
    
    def _calculate_closeness(self, adj_matrix: np.ndarray, node: int) -> float:
        """Closeness centrality: 1 / average distance to all other nodes."""
        n = len(adj_matrix)
        if n <= 1:
            return 0
        
        # BFS to find distances
        distances = self._bfs_distances(adj_matrix, node)
        reachable = [d for d in distances if d > 0]
        
        if not reachable:
            return 0
        
        avg_distance = np.mean(reachable)
        return 1 / avg_distance if avg_distance > 0 else 0
    
    def _bfs_distances(self, adj_matrix: np.ndarray, source: int) -> List[int]:
        """BFS to find distances from source to all other nodes."""
        n = len(adj_matrix)
        distances = [-1] * n
        distances[source] = 0
        
        queue = deque([source])
        
        while queue:
            current = queue.popleft()
            current_dist = distances[current]
            
            for neighbor in range(n):
                if adj_matrix[current][neighbor] and distances[neighbor] == -1:
                    distances[neighbor] = current_dist + 1
                    queue.append(neighbor)
        
        return distances
    
    def _calculate_clustering(self, adj_matrix: np.ndarray, node: int) -> float:
        """Clustering coefficient: fraction of neighbor pairs that are also connected."""
        n = len(adj_matrix)
        neighbors = [i for i in range(n) if adj_matrix[node][i]]
        
        if len(neighbors) < 2:
            return 0
        
        # Count edges between neighbors
        edges = 0
        for i in neighbors:
            for j in neighbors:
                if i < j and adj_matrix[i][j]:
                    edges += 1
        
        max_edges = len(neighbors) * (len(neighbors) - 1) / 2
        return edges / max_edges if max_edges > 0 else 0
    
    def detect_clusters(
        self,
        profiles: Dict[str, InsiderProfile],
        transactions: List[InsiderTransaction]
    ) -> List[InsiderCluster]:
        """Detect clusters of connected insiders using community detection."""
        # Build connected components using Union-Find
        names = list(profiles.keys())
        parent = {name: name for name in names}
        
        def find(x):
            if parent[x] != x:
                parent[x] = find(parent[x])
            return parent[x]
        
        def union(x, y):
            px, py = find(x), find(y)
            if px != py:
                parent[px] = py
        
        # Union connected insiders
        for name, profile in profiles.items():
            for connected in profile.connected_insiders:
                if connected in parent:
                    union(name, connected)
        
        # Group by cluster
        clusters_dict = defaultdict(list)
        for name in names:
            root = find(name)
            clusters_dict[root].append(name)
        
        # Build cluster objects
        clusters = []
        for cluster_id, members in enumerate(clusters_dict.values(), 1):
            if len(members) < 2:
                continue
            
            # Get companies
            companies = set()
            total_value = 0
            sync_times = []
            
            for member in members:
                profile = profiles[member]
                companies.update(profile.companies)
                total_value += profile.total_buy_value + profile.total_sell_value
            
            # Calculate average transaction synchronization
            member_txns = [t for t in transactions if t.insider_name in members]
            dates = [datetime.strptime(t.transaction_date, '%Y-%m-%d') for t in member_txns]
            if len(dates) > 1:
                dates.sort()
                time_diffs = [(dates[i+1] - dates[i]).days for i in range(len(dates)-1)]
                avg_sync = np.mean(time_diffs) if time_diffs else 0
            else:
                avg_sync = 0
            
            # Classify cluster type
            if len(companies) == 1:
                cluster_type = "EXECUTIVE_GROUP"
            elif all("board" in p.titles[0].lower() for m in members for p in [profiles[m]]):
                cluster_type = "BOARD_NETWORK"
            else:
                cluster_type = "CROSS_COMPANY"
            
            clusters.append(InsiderCluster(
                cluster_id=cluster_id,
                members=sorted(members),
                size=len(members),
                companies=sorted(companies),
                total_transaction_value=total_value,
                avg_transaction_sync=round(avg_sync, 1),
                cluster_type=cluster_type
            ))
        
        return sorted(clusters, key=lambda x: x.size, reverse=True)
    
    def generate_report(
        self,
        tickers: List[str],
        days: int = 365
    ) -> InsiderNetworkReport:
        """Generate full insider trading network analysis report."""
        # Fetch transactions for all tickers
        all_transactions = []
        for ticker in tickers:
            try:
                txns = self.fetch_insider_trades(ticker, days)
                all_transactions.extend(txns)
            except Exception as e:
                print(f"Warning: Could not fetch {ticker} insider data: {e}")
        
        if not all_transactions:
            # Return empty report if no data
            return InsiderNetworkReport(
                analysis_date=datetime.now().strftime('%Y-%m-%d'),
                tickers=tickers,
                total_insiders=0,
                total_transactions=0,
                time_range_days=days,
                top_insiders=[],
                coordinated_activities=[],
                network_metrics=[],
                clusters=[],
                buy_sell_ratio=0,
                summary="No insider trading data available for analysis period.",
                red_flags=[]
            )
        
        # Build profiles
        profiles = self.build_insider_profiles(all_transactions)
        
        # Detect coordinated activity
        coordinated = self.detect_coordinated_activity(all_transactions)
        
        # Calculate network metrics
        network_metrics = self.calculate_network_metrics(profiles)
        
        # Detect clusters
        clusters = self.detect_clusters(profiles, all_transactions)
        
        # Calculate buy/sell ratio
        total_buys = sum(p.total_buy_value for p in profiles.values())
        total_sells = sum(p.total_sell_value for p in profiles.values())
        buy_sell_ratio = total_buys / total_sells if total_sells > 0 else 0
        
        # Generate red flags
        red_flags = []
        if coordinated:
            red_flags.append(f"Detected {len(coordinated)} potentially coordinated trading patterns")
        if buy_sell_ratio < 0.3:
            red_flags.append(f"Heavy insider selling (buy/sell ratio: {buy_sell_ratio:.2f})")
        if buy_sell_ratio > 3.0:
            red_flags.append(f"Heavy insider buying (buy/sell ratio: {buy_sell_ratio:.2f})")
        
        large_clusters = [c for c in clusters if c.size >= 5]
        if large_clusters:
            red_flags.append(f"Detected {len(large_clusters)} large insider clusters (5+ members)")
        
        # Generate summary
        top_5 = sorted(profiles.values(), key=lambda p: abs(p.net_position), reverse=True)[:5]
        summary = (
            f"Analyzed {len(profiles)} insiders across {len(tickers)} companies over {days} days. "
            f"Total transactions: {len(all_transactions)}. "
            f"Buy/sell ratio: {buy_sell_ratio:.2f}. "
        )
        
        if coordinated:
            summary += f"Found {len(coordinated)} coordinated trading patterns. "
        if clusters:
            summary += f"Identified {len(clusters)} insider clusters. "
        
        return InsiderNetworkReport(
            analysis_date=datetime.now().strftime('%Y-%m-%d'),
            tickers=tickers,
            total_insiders=len(profiles),
            total_transactions=len(all_transactions),
            time_range_days=days,
            top_insiders=sorted(profiles.values(), key=lambda p: abs(p.net_position), reverse=True)[:10],
            coordinated_activities=coordinated[:20],
            network_metrics=network_metrics[:20],
            clusters=clusters[:10],
            buy_sell_ratio=round(buy_sell_ratio, 2),
            summary=summary,
            red_flags=red_flags
        )


# Convenience functions for CLI
def analyze_network(tickers: List[str], days: int = 365) -> dict:
    """Analyze insider trading network for given tickers."""
    analyzer = InsiderNetworkAnalyzer()
    report = analyzer.generate_report(tickers, days)
    return asdict(report)


def find_coordinated_trades(tickers: List[str], window_days: int = 5) -> dict:
    """Find coordinated insider trades within time window."""
    analyzer = InsiderNetworkAnalyzer()
    all_txns = []
    for ticker in tickers:
        try:
            txns = analyzer.fetch_insider_trades(ticker, days=365)
            all_txns.extend(txns)
        except:
            pass
    
    coordinated = analyzer.detect_coordinated_activity(all_txns, window_days)
    return {
        'coordinated_activities': [asdict(c) for c in coordinated],
        'total_found': len(coordinated)
    }


def get_network_metrics(tickers: List[str]) -> dict:
    """Get network centrality metrics for insiders."""
    analyzer = InsiderNetworkAnalyzer()
    all_txns = []
    for ticker in tickers:
        try:
            txns = analyzer.fetch_insider_trades(ticker, days=365)
            all_txns.extend(txns)
        except:
            pass
    
    if not all_txns:
        return {'error': 'No insider data available'}
    
    profiles = analyzer.build_insider_profiles(all_txns)
    metrics = analyzer.calculate_network_metrics(profiles)
    
    return {
        'network_metrics': [asdict(m) for m in metrics],
        'total_insiders': len(profiles)
    }


if __name__ == '__main__':
    # Test with example ticker
    print("Insider Network Analyzer - Phase 91")
    print("=" * 50)
    
    analyzer = InsiderNetworkAnalyzer()
    report = analyzer.generate_report(['AAPL'], days=180)
    
    print(f"\nAnalysis Date: {report.analysis_date}")
    print(f"Tickers: {', '.join(report.tickers)}")
    print(f"Total Insiders: {report.total_insiders}")
    print(f"Total Transactions: {report.total_transactions}")
    print(f"Buy/Sell Ratio: {report.buy_sell_ratio}")
    print(f"\nSummary: {report.summary}")
    
    if report.red_flags:
        print("\n‚ö†Ô∏è  Red Flags:")
        for flag in report.red_flags:
            print(f"  - {flag}")
    
    if report.coordinated_activities:
        print(f"\nüîç Top Coordinated Activities:")
        for activity in report.coordinated_activities[:3]:
            print(f"  - {activity.transaction_type}: {len(activity.insiders)} insiders, "
                  f"${activity.total_value:,.0f}, confidence {activity.confidence}%")
    
    if report.network_metrics:
        print(f"\nüìä Top Network Influencers:")
        for metric in report.network_metrics[:5]:
            print(f"  - {metric.name}: influence score {metric.influence_score}")
